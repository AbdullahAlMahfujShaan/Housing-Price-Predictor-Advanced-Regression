{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_all = 'G:/DeepLearning/Housing Price Prediction/Data Sets/'\n",
    "dataset = 'G:/DeepLearning/Housing Price Prediction/Data Sets/data_description.txt'\n",
    "path_train = 'G:/DeepLearning/Housing Price Prediction/Data Sets/train.csv'\n",
    "path_test = 'G:/DeepLearning/Housing Price Prediction/Data Sets/test.csv'\n",
    "house_data = pd.read_csv(path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(house_data.columns[house_data.isna().any()].tolist())\n",
    "len(house_data.columns[house_data.isna().any()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "house_data.hist(bins =50, figsize=(30,25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def split_train_test(data,test_ratio):\n",
    "   # shuffled_indices = np.random.permutation(len(data))\n",
    "    #test_set_size = int(len(data)* test_ratio)\n",
    "    #test_indices = shuffled_indices[:test_set_size]\n",
    "    #train_indices = shuffled_indices[test_set_size:]\n",
    "    #return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set, test_set = split_train_test(dataset, 0.15)\n",
    "#len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in house_data.columns if x not in ['SalePrice']]\n",
    "X = house_data[features]\n",
    "y = house_data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = house_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"Id\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix \n",
    "attributes = [\"Id\",\"PoolArea\",\"BedroomAbvGr\",\"TotRmsAbvGrd\",\"MoSold\",\"GarageArea\",       \n",
    "\"GarageCars\",\"OverallCond\",\"MSSubClass\",\"1stFlrSF\",\"GrLivArea\",\"HalfBath\",         \n",
    "\"2ndFlrSF\",\"FullBath\",\"KitchenAbvGr\",\"EnclosedPorch\",\"BsmtFullBath\",\"ScreenPorch\",\"YrSold\",           \n",
    "\"GarageYrBlt\",\"OpenPorchSF\",\"BsmtFinSF1\",\"BsmtFinSF2\",\"MiscVal\",         \n",
    "\"BsmtUnfSF\",\"LotFrontage\",\"YearBuilt\",\"TotalBsmtSF\",\"Fireplaces\",\"BsmtHalfBath\",    \n",
    "\"SalePrice\",\"YearRemodAdd\",\"OverallQual\",\"WoodDeckSF\",\"LotArea\",\"LowQualFinSF\",    \n",
    "\"3SsnPorch\",\"MasVnrArea\"]\n",
    "scatter_matrix(house_data[attributes], figsize = (100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=1)\n",
    "\n",
    "numerical_cols = [cname for cname in X_train.columns if \n",
    "                X_train[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "categorical_cols = [cname for cname in X_train.columns if\n",
    "                    X_train[cname].nunique() < 10 and \n",
    "                    X_train[cname].dtype == \"object\"]\n",
    "\n",
    "\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_model = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "tree_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('tree_model', tree_model)\n",
    "                     ])\n",
    "\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "tree_preds = tree_clf.predict(X_valid)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_valid, tree_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_model = RandomForestRegressor(random_state=0)\n",
    "\n",
    "random_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('random_model', random_model)\n",
    "                     ])\n",
    "\n",
    "random_clf.fit(X_train, y_train)\n",
    "\n",
    "random_clf.fit(X_train, y_train)\n",
    "\n",
    "random_preds = random_clf.predict(X_valid)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_valid, random_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=1000, learning_rate=0.07, random_state=0)\n",
    "\n",
    "xgb_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('xgb_model', xgb_model)\n",
    "                     ])\n",
    "\n",
    "xgb_clf.fit(X_train, y_train, xgb_model__verbose=False)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "xgb_preds = xgb_clf.predict(X_valid)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_valid, xgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.6, gamma=0.5, gpu_id=1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.02, max_delta_step=0, max_depth=4,\n",
    "             min_child_weight=1, monotone_constraints='1',\n",
    "             n_estimators=1000, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
    "             tree_method='exact', validate_parameters=1, verbosity= 0)\n",
    "\n",
    "hp_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('hp_model', hp_model)\n",
    "                     ])\n",
    "\n",
    "hp_clf.fit(X_train, y_train, hp_model__verbose= 0)\n",
    "\n",
    "hp_preds = hp_clf.predict(X_valid)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_valid, hp_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X['YearBuilt'].head())\n",
    "print(X['YearRemodAdd'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X['LotArea'].head())\n",
    "print(X['LotFrontage'].head())\n",
    "print(set(X['LandSlope']))\n",
    "print(set(X['LandContour']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(X['YrSold']))\n",
    "print(set(X['MoSold']))\n",
    "print(set(X['Condition1']))\n",
    "print(set(X['Condition2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(X['ExterQual']))\n",
    "print(set(X['ExterCond']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat_eng = X.copy()\n",
    "X_feat_eng['years_since_update'] = X_feat_eng['YearRemodAdd'] - X_feat_eng['YearBuilt']\n",
    "X_feat_eng['geometry'] = X_feat_eng['LotArea'] / X_feat_eng['LotFrontage']\n",
    "X_feat_eng['land_topology'] = X_feat_eng['LandSlope'] + '_' + X_feat_eng['LandContour']\n",
    "\n",
    "feature_numerical_cols = [cname for cname in X_feat_eng.columns if \n",
    "                X_feat_eng[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "feature_categorical_cols = [cname for cname in X_feat_eng.columns if\n",
    "                    X_feat_eng[cname].nunique() < 13 and \n",
    "                    X_feat_eng[cname].dtype == \"object\"]\n",
    "\n",
    "\n",
    "feature_numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "feature_categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "feature_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', feature_numerical_transformer, feature_numerical_cols),\n",
    "        ('cat', feature_categorical_transformer, feature_categorical_cols)\n",
    "])\n",
    "\n",
    "feature_model = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.6, gamma=0.0, gpu_id=1,\n",
    "             importance_type='gain', interaction_constraints='',\n",
    "             learning_rate=0.02, max_delta_step=0, max_depth=4,\n",
    "             min_child_weight=0.0, monotone_constraints='1',\n",
    "             n_estimators=1325, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=0)\n",
    "feature_clf = Pipeline(steps=[('feature_preprocessor', feature_preprocessor),\n",
    "                      ('feature_model', feature_model)\n",
    "                     ])\n",
    "\n",
    "feature_X_train, feature_X_valid, feature_y_train, feature_y_valid = train_test_split(X_feat_eng, y, random_state=0)\n",
    "\n",
    "feature_clf.fit(feature_X_train, feature_y_train, feature_model__verbose=0)\n",
    "\n",
    "feature_preds = feature_clf.predict(feature_X_valid)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(feature_y_valid, feature_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['years_since_update'] = X_test['YearRemodAdd'] - X_test['YearBuilt']\n",
    "X_test['geometry'] = X_test['LotArea'] / X_test['LotFrontage']\n",
    "X_test['land_topology'] = X_test['LandSlope'] + '_' + X_test['LandContour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = feature_clf.predict(X_test)\n",
    "output = pd.DataFrame({'Id': X_test.Id,\n",
    "                       'SalePrice': preds})\n",
    "output.to_csv('G:/DeepLearning/Housing Price Prediction/Data Sets/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = feature_clf.predict(X_test)\n",
    "output = pd.DataFrame({'Id': X_test.Id,\n",
    "                       'SalePrice': preds})\n",
    "output.to_csv('G:/DeepLearning/Housing Price Prediction/Data Sets/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Housing Price Prediction",
   "language": "python",
   "name": "housingprice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
